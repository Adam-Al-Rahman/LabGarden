{
  
    
        "post0": {
            "title": "Neural Network Regression",
            "content": "What is a Regression Problems? . Example: . How much will this house sell for? | How many people will buy this app? | How much will my health insurance be? | How much should I save each week for fuel? | .",
            "url": "https://adam-al-rahman.github.io/LabGarden/neural-network/regression/machine_learning/tensorflow/2022/01/01/ML-NNR.html",
            "relUrl": "/neural-network/regression/machine_learning/tensorflow/2022/01/01/ML-NNR.html",
            "date": " • Jan 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Tensorflow Fundamentals",
            "content": "import tensorflow as tf print(tf.__version__) . 2.6.0 . scalar = tf.constant(7) scalar . &lt;tf.Tensor: shape=(), dtype=int32, numpy=7&gt; . scalar.ndim . 0 . vector = tf.constant([10, 10]) vector . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10])&gt; . vector.ndim . 1 . matrix = tf.constant([[10, 7], [7, 10]]) matrix . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[10, 7], [ 7, 10]])&gt; . matrix.ndim . 2 . another_matrix = tf.constant([[10., 7.], [3., 2.], [8., 9.]], dtype=tf.float16) another_matrix . &lt;tf.Tensor: shape=(3, 2), dtype=float16, numpy= array([[10., 7.], [ 3., 2.], [ 8., 9.]], dtype=float16)&gt; . another_matrix.ndim . 2 . tensor = tf.constant( [ [ [1, 2, 3], [4, 5, 6], ], [ [7, 8, 9], [10, 11, 12] ], [ [13, 14, 15], [16, 17, 18] ] ] ) tensor . &lt;tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy= array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]], [[13, 14, 15], [16, 17, 18]]])&gt; . tensor.ndim . 3 . tf.Variable . tensorflow.python.ops.variables.Variable . changable_tensor = tf.Variable([10, 7]) unchangable_tensor = tf.constant([10, 7]) changable_tensor, unchangable_tensor . (&lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([10, 7])&gt;, &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 7])&gt;) . %%script echo &quot;TypeError: &#39;ResourceVariable&#39; object does not support item assignment&quot; # Lets try change one of the elements in our changable tensor changable_tensor[0] = 7 changable_tensor . TypeError: &#39;ResourceVariable&#39; object does not support item assignment . changable_tensor[0].assign(7) changable_tensor . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([7, 7])&gt; . %%script echo &quot;AttributeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object has no attribute &#39;assign&#39;&quot; # Let&#39;s try change our un-changable tensor unchangable_tensor[0].assign(7) unchangable_tensor . AttributeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object has no attribute &#39;assign&#39; . random_1 = tf.random.Generator.from_seed(42) # Set seed for reproducibility random_1 = random_1.normal(shape=(3, 2)) # probability is constant random_2 = tf.random.Generator.from_seed(42) random_2 = random_2.normal(shape=(3,2)) # Are they equal? random_1, random_2, random_1 == random_2 . (&lt;tf.Tensor: shape=(3, 2), dtype=float32, numpy= array([[-0.7565803 , -0.06854702], [ 0.07595026, -1.2573844 ], [-0.23193765, -1.8107855 ]], dtype=float32)&gt;, &lt;tf.Tensor: shape=(3, 2), dtype=float32, numpy= array([[-0.7565803 , -0.06854702], [ 0.07595026, -1.2573844 ], [-0.23193765, -1.8107855 ]], dtype=float32)&gt;, &lt;tf.Tensor: shape=(3, 2), dtype=bool, numpy= array([[ True, True], [ True, True], [ True, True]])&gt;) . Shuffle the order of elements i a tensors . not_shuffled = tf.constant( [ [10, 7], [3, 4], [2, 5] ] ) # Shuffle our non-shuffled tensor shuffled=tf.random.shuffle(not_shuffled, seed=42, name=&quot;Shuffle&quot;) not_shuffled.ndim, shuffled . (2, &lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy= array([[ 2, 5], [ 3, 4], [10, 7]])&gt;) . tf.random.set_seed(42) tf.random.shuffle(not_shuffled, seed=42) . &lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy= array([[10, 7], [ 3, 4], [ 2, 5]])&gt; . tf.random.set_seed(54) tf.random.shuffle(not_shuffled) . &lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy= array([[ 2, 5], [ 3, 4], [10, 7]])&gt; . tf.random.set_seed(54) # global level random seed tf.random.shuffle(not_shuffled, seed=32) # operation level random seed . &lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy= array([[ 2, 5], [ 3, 4], [10, 7]])&gt; . Other ways to make tensors . tf.ones([10, 7]) . &lt;tf.Tensor: shape=(10, 7), dtype=float32, numpy= array([[1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)&gt; . tf.zeros(shape=(3, 4)) . &lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy= array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]], dtype=float32)&gt; . Turn NumPy array into tensors . The main difference between Numpy array and Tensorflow tensors is that tensors can be run on a GPU computing . import numpy as np numpy_A= np.arange(1, 25, dtype=np.int32) # create a NumPy array between 1 and 25. numpy_A . array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]) . A = tf.constant(numpy_A, shape=(2, 3, 4)) A . &lt;tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy= array([[[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]], [[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]])&gt; . A.ndim . 3 . Getting information from tensors . Shape | Rank | Axis or dimension | Size | . Tensor Attributes . Attribute Meaning Code . Shape | The length(number of elements) of each of the dimensions of a tensor | tensor.shape | . Rank | The number of tensor dimension. A scalar has rank 0, a vector has rank 1, a matrix is rank 2, a tensor has rank n. | tensor.ndim | . Axis or dimension | A particular dimension of a tensor | tensor[0], tensor[:,1] | . Size | The total number of items in the tensor | tf.size(tensor) | . rank_4_tensor = tf.zeros(shape=[2, 3, 4, 5]) rank_4_tensor, rank_4_tensor.ndim . (&lt;tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy= array([[[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]], [[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]]], dtype=float32)&gt;, 4) . rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor) . (TensorShape([2, 3, 4, 5]), 4, &lt;tf.Tensor: shape=(), dtype=int32, numpy=120&gt;) . def TensorAttributes(tensor): tf.print(&quot;Datatypes of every element: &quot;, tensor.dtype) tf.print(&quot;Number of dimensions (rank): &quot;, tensor.ndim) tf.print(&quot;Shape of tensor: &quot;, tensor.shape) tf.print(&quot;Elements along the 0 axis: &quot;, tensor.shape[0]) tf.print(&quot;Elements along the last axis: &quot;, tensor.shape[-1]) tf.print(&quot;Total number of elements in our tensor: &quot;, tf.size(tensor)) TensorAttributes(rank_4_tensor) . Datatypes of every element: tf.float32 Number of dimensions (rank): 4 Shape of tensor: TensorShape([2, 3, 4, 5]) Elements along the 0 axis: 2 Elements along the last axis: 5 Total number of elements in our tensor: 120 . rank_4_tensor[:1, :1, :1] . &lt;tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)&gt; .",
            "url": "https://adam-al-rahman.github.io/LabGarden/machine_learning/tensorflow/2021/11/09/00-tf-fund.html",
            "relUrl": "/machine_learning/tensorflow/2021/11/09/00-tf-fund.html",
            "date": " • Nov 9, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "What is Neural Network?",
            "content": "Inputs -&gt; Numerical encoding -&gt; Learn representation (patterns/feature/weights) -&gt; Representation outputs -&gt; Outputs . Anatomy of Neural Network . Input Layers | Hidden Layers | Output Layers | . Type of Learning . Supervised Learning. | Semi-Supervised Learning. | Unsupervised Learning. | Transfer Learning. | Reinforcement Learning. | . What is deep learning actually used for? . Deep learning is for making neural network for neural network and making in the working. . Deep Learning some use cases . Recommendation. | Translation. [Sequence to Sequence (seq2seq)]. | Speech Recognition. | Computer Vision. | Natural Language Processing (NPL) [Classification | Regression]. | . What is and why use Tensorflow? . End-to-End platform for machine learning | Write fast deep leaning code in Python/other accessible languages(able to run on a GPU/TPU) | Able to access many pre-built deep learning models(TensorFlow Hub) | Whole stack: preprocess data, model data, deploy model in your application. | Originally designed and used in house by Google ( now open - source) | . What is a Tensor? . A tensor is an algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space. .",
            "url": "https://adam-al-rahman.github.io/LabGarden/machine_learning/tensorflow/2021/11/02/TF-Intro.html",
            "relUrl": "/machine_learning/tensorflow/2021/11/02/TF-Intro.html",
            "date": " • Nov 2, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Machine Learning Framework",
            "content": "The framework comprises six steps . . Steps in Data Modelling: . Problem Definition: &quot;What problem are we trying to solve?&quot; . Supervised. | Unsupervised. | Classification. | Regression. | . | Data: &quot;What data do we have?&quot; . Structured. | Unstructured. | . | Evalution: &quot;What defines succes for us?&quot; . | Features: &quot;What do we already know about the data?&quot; . | Modelling: &quot;Based on our problem and data, what model should we use?&quot; . | Experimentation: &quot;How could we improve?/what else can we try?&quot; . | 1. Types of Machine Learning problems . Supervised Learning: . It is called Supervise Learning, because here we have data and labels. Here a machine learning algorithms tries to use the data to predict a label. . If it guesses the label wrong, the algorithms corrects itself and tries again. This active correction why is called Supervise . Main type of Supervised Learning problems: . Classification: . &quot;Is this example one thing or another?&quot; | Binary classification = two options | Multi-class classification = more than two options | . | Regression: . &quot;How much will this house sell for?&quot; | &quot;How many people will buy this app?&quot; | . | Unsupervised Learning . It has data but no labels . Main types of Unsupervised Learning problems: . Cluster: Grouping the labels. | . | Transfer Learning . Use the pre-build model for similar project to predict and customize it to make it precise that aren&#39;t cover in pre-build model. . Reinforcment Learning . +1 if the model do correct. | -1 if the model do wrong. | . 2. Data . Types of Data . Structured data : . CSV (comma separated values) | excel sheet | . | Unstructured data : . Images. | voices. | Natural language processing. | . | ### Static data : Data that does not change over time. eg : Csv,... . | ### Streaming data : Data that changes over time. eg : stock, news,... . | . Workflow . Static / streaming =&gt; jupyter-lab =&gt; Data_Analysis (pandas) =&gt; matplotlib/plotly =&gt; machine_learning_model (tensorflow / Scikit learn) =&gt; results . 3. Evaluation : &quot;What defines success for us?&quot; . Different types fo metrics . Classification Regression Recommendation . Accuracy | Mean absolute error (MAE) | precision at K | . Precision | Mean squared error (MSE) | | . Recall | Root mean squared error (RMSE) | | . 4 Features in Data : What do we already know about the data? . Use Feature variable (weight, heart rate) to predict Target variable (Heart disease?) . Numerical Feature : A number like body weigth . | Categorial features : Like one in two (yes / no) . | Derived feature : Look at the data and create new feature using the existing one. . Feature Engineering: Looking at different features of data and creating new ones/altering existing ones. . | . . Feature Coverage: How many samples have different features? Ideally, every sample has the same features. . What are features of your problems? . 5. Modelling : . I. Choosing and training a model. [Training data] . II. Tuning a model. [Validatin data] . III. Model comparison. [Test data] . The most important concept in machine learning. . (The training, validation and test sets or $ boxed{3 sets}$) . Split data into : . Training [Train your model on this ] : 70-80% | Validation [Tune your model on this ] : 10-15% | Test [ Test and compare on this ] : 10-15% | . All the split are different. . When thing go wrong? . When Test is revealed before the time. . Modelling : Picking the model . Problem-1 =&gt; Model-1 . Problem-2 =&gt; Model-2 . Sturctured Data . CatBoost | dmlc XGBoost | Random Forest | . Unstructured Data . Deep learning. | Transfer learning. | . Training a Model . X(data): . - Weight - Sex - heart rate - chest pain . y(label) . - Heart disease? . Goal :Minize time between experiments Experiment . Input =&gt; Model-1 =&gt; Accurary | Training-Time | Prediction-Time | . Thing to remember . Some models work better than other on different problems. | Don&#39;t be afraid to try things. | Start small and build up (add complexit) as you need. | . Modelling : Tuning . Random Forest: . Allow to adjust number of tree. . Neural network: . Allow to adjust number of hidden layers. . Things to remember: . Machine learning model have hyperparameters you can adjust. | A models first result aren&#39;t its last. | Tuning can take place on training or validation data sets. | . Modeling : comparison . Testing a model . Right Way : . Balanced [Goldilocks Zone] | . Data Set Performace . Training | 98% | . Test | 96% | . . Wrong Way : . Underfitting [Potential] | . Data Set Performace . Training | 64% | . Test | 47% | . Overfitting [Potential] | . Data Set Performace . Training | 93% | . Test | 99% | . . Overfitting and underfitting . Data Leakage : . This happens when Training data leaks into Test data, Which make occurs of Overfitting . Data Mismatch : . This happen when Training data is different than Test data, Which lead to Underfitting . Fixes for overfitting and underfitting . Underfitting : . Try a more advanced model. | Increase model hyperparameters. | Reduce amount of features. | Train longer. | . Overfitting : . collect more data. | Try a less advanced model. | . Thing to remember . Want to avoid overfitting and underfitting (head towards generality) | keep the test set separate at all costs. | Compare apples to apples. | One best performance metric does not equal best model | . Overfitting and Underfitting Definitions . All experiments should be conducted on different portions of your data. . Training data set — Use this set for model training, 70–80% of your data is the standard. . Validation/development data set — Use this set for model hyperparameter tuning and experimentation evaluation, 10–15% of your data is the standard. . Test data set — Use this set for model testing and comparison, 10–15% of your data is the standard. . These amounts can fluctuate slightly, depending on your problem and the data you have. . Poor performance on training data means the model hasn’t learned properly and is underfitting. Try a different model, improve the existing one through hyperparameter or collect more data. . Great performance on the training data but poor performance on test data means your model doesn’t generalize well. Your model may be overfitting the training data. Try using a simpler model or making sure your the test data is of the same style your model is training on. . Another form of overfitting can come in the form of better performance on test data than training data. This may mean your testing data is leaking into your training data (incorrect data splits) or you&#39;ve spent too much time optimizing your model for the test set data. Ensure your training and test datasets are kept separate at all times and avoid optimizing a models performance on the test set (use the training and validation sets for model improvement). . Poor performance once deployed (in the real world) means there’s a difference in what you trained and tested your model on and what is actually happening. Ensure the data you&#39;re using during experimentation matches up with the data you&#39;re using in production. . Fullscreen . Experimentation: &quot;What have tried/ what else can we try?&quot; . Doing experimentation with input hyperparameter, until hit the spot. .",
            "url": "https://adam-al-rahman.github.io/LabGarden/machine_learning/deep_learning/artificial_learning/ml_framework/2021/10/31/ML-FrmWk.html",
            "relUrl": "/machine_learning/deep_learning/artificial_learning/ml_framework/2021/10/31/ML-FrmWk.html",
            "date": " • Oct 31, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "What is Machine Learning?",
            "content": "Machine Learning and Deep Learning are subset of Artificial Intelligence. . Deep Learning : . Extract patterns from data using neural networks. . Aim of Deep Learning: . To build neural networks that automatically discover patterns for feature detection. . Machine Learning Another Definition: . It is a way to convert things(data) into numbers and find patterns in those number. . Aim of Machine Learning: . To make machine learn through data so that they can solve problems. . Artificial Intelligence: . Any technique that enables computer to mimic human behavior. . Aim of Artificial Intelligence: . To build machines which are capable of thinking like human or doing human tasks. . Structure of AI . Source : The Taxonomy of Artificial Intelligence and Data Science . Data -&gt; Machine learning alogrithm(model) -&gt; Patterns . Narrow AI : The machine AI which is good at specific task only one thing. . General AI : The AI machine which good at many task. . How did we get Here? . In early stage to collect data we used Spreadsheets. CSV | Excel | . | . As the data grow the new technologies appeard . Relational DataBase(DB) MySQL (Query language to to CRUD operation) | CRUD : Create Read Update Delete. | . | . And as the data grow more and more. In 2000 we got the fancy term called Big data . Big data MongoDB (NoSQL) | . | . Now we have collect alot of data and to utilize that in Machine learning as data source. . Steps in a full Machine learning project . . Data Science : To utilize the huge data. . Types of Machine Learning : . Supervised Learning : . Classification. Classifying is this(relative) a apple or mango. | Regression. like predicting stock prices. | . | Semi-Supervised Learning : . This include the character of both supervised and unsupervised learning. | . | Unsupervised Learning : . Clustering. Making group of the similar data and then predict. | Association Rule Learning. | . | Reinforcement Learning . Skill acquisition. | Real time learning. | . | . Exercise Machine Learning Playground . Teachable Machine . Quotes . .",
            "url": "https://adam-al-rahman.github.io/LabGarden/machine_learning/deep_learning/artificial_learning/2021/10/27/ML-101.html",
            "relUrl": "/machine_learning/deep_learning/artificial_learning/2021/10/27/ML-101.html",
            "date": " • Oct 27, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hello, I&#39;m Atiq and I enjoy reading, researching &amp; creating things. My interest in coding started, when I heard python in one of a physics videos. . Fast-forward to today, and I’ve the privilege to study in one of the well known college in India UPES located at Dehradun. . Right now, I&#39;m pursuing my bachelor degree in computer science. . Portfolio .",
          "url": "https://adam-al-rahman.github.io/LabGarden/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://adam-al-rahman.github.io/LabGarden/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}